{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"font-family: 'Palatino Linotype', serif;\">üêâ A batalha final! </span>**\n",
    "\n",
    "*<span style=\"font-family: 'Angilla Tattoo'\"> <span style=\"font-family: 'Angilla Tattoo'\"> Nos dados forjamos nossas espadas, no c√≥digo afiamos nossas l√¢minas ‚Äì e hoje, enfrentamos o drag√£o final da complexidade. O conhecimento √© nossa maldi√ß√£o e a m√°quina nossa arma. </span>*\n",
    "<div align=\"center\">\n",
    "    <img src=\"assets\\mapas\\4.png\" alt=\"Mapa: A Batalha Final\">\n",
    "    <figcaption>A grande fera encontra nossos her√≥is (ou o oposto?)</figcaption>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trabalho Final: üå≥xüèòÔ∏èConclus√£o: Comparando modelos**\n",
    "==========================================================\n",
    "\n",
    "\n",
    "\n",
    "**Autores:** Sepulcro de Delfos\n",
    "\n",
    "* Ana Luz\n",
    "\n",
    "* Caio Ruas\n",
    "\n",
    "* Caio Matheus\n",
    "\n",
    "* Giovana Martins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è **Analisando modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso trabalho, utilizamos os modelos de previs√£o **k-NN vizinhos** e **√°rvore de decis√£o** para realizar a predi√ß√£o dos dataset de propriedades dos materiais.\n",
    "\n",
    "Primeiramente, vamos entender as diferen√ßas te√≥ricas dos modelos:\n",
    "\n",
    "**k-NN vizinhos:** Esse modelo realiza a predi√ß√£o do target com base na an√°lise dos vizinhos **k** mais pr√≥ximos do novo dado observado. O modelo compara os valores de atributo apresentados para a previs√£o do target com os valores mais pr√≥ximos existentes no dataset, e a partir desse ponto, realizar a predi√ß√£o. A predi√ß√£o pode ser determinada tanto pela m√©dia dos vizinhos (regrss√£o) quanto pelo valor da maioria (classifica√ß√£o).\n",
    "\n",
    "**√Årvore de decis√£o:** Esse modelo ir√° realizar \"perguntas\" para classificar os novos dados apresentados. Para isso, ser√£o formados **n√≥s** dentro do modelo; cada n√≥ ir√° realizar uma pergunta sobre as caracter√≠sticas do dado. Com base na resposta, o dado √© encaminhado para outro n√≥ at√© chegar a uma folha, onde a classifica√ß√£o final √© feita. Nesse modelo, definimos uma quantidade m√°xima de n√≥s e uma qunatidade m√≠nima de dados por n√≥, o que evita que o modelo sobre *overfitting* ou *underfitting*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üó°Ô∏è Vantagens e desvantagens:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-NN vizinhos:**\n",
    "\n",
    "‚úÖ√â um modelo simples, que n√£o precisa passar por fase de treinamento e que se adapta bem tanto a regress√£o quanto a classifica√ß√£o. \n",
    "\n",
    "‚ùåPrecisa de dados normalizados e bem ajustadados, pois considera todos os vizinhos, inclusive aqueles que n√£o s√£o representativos. \n",
    "\n",
    "\n",
    "**√Årvore de decis√£o**\n",
    "\n",
    "‚úÖ Se trata de um modelo bastante visual, em que interpretar e enxergar as rela√ß√µes n√£o lineare de vari√°ves se torna mais f√°cil. Geralmente n√£o exige uma prepara√ß√£o dos dados como normaliza√ß√µes.\n",
    "\n",
    "‚ùå Estamos falando de um modelo menos preciso, que √© marcado por instabilidades, j√° que algumas poucas mudan√ßas nos dados j√° causaria varia√ß√µes significativas do modelo. Al√©m disso, n√£o √© incomum ter *overfitting*, pois perde sua capacidade de generaliza√ß√£o a medida que se ajusta muito aos dados de modelagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚öîÔ∏èComparando nossas miss√µes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de analisar e entender as caracter√≠sticas desses dois modelos podemos comparar os valores das m√©tricas de desempenho dessas duas formas de predi√ß√£o. Ent√£o iremos apresentar e comentar alguns valores que foram calcul√°dos nos notebooks ateriores, por isso caso tenha d√∫vidas sobre algum valor sugerimos que retorne aos notebooks anteriores.\n",
    "\n",
    "\n",
    "| Modelo   | MSE | RMSE     | M√©dia (dados previstos)|\n",
    "| ---   | ---   | ---      |  ---    |\n",
    "| K-nn Vizinhos   | 3.337   | 1.826   | 1.367 |\n",
    "| √Årvore de decis√£o | 1.098   | 1.234   | 2.302 |\n",
    "\n",
    "M√©dia do Dataframe: 2.290\n",
    "\n",
    "Olhando  para a tabela acima observamos uma coisa curiosa, os valores que indicam uma melhor precis√£o est√£o mais baixos (melhores) na √°rvore de decis√£o. Ent√£o, est√£o indo na contram√£o ao que seria intuitivo de pensar, o modelo que fez as melhores previs√µes foi o segundo. O que mostra que definir um melhor modelo √© uma tarefa que envolve contexto, finalidade e formato dos dados.\n",
    "\n",
    "Mas podemos pensar mais al√©m dessa compara√ß√£o num√©rica, visitando os dois histogramas, percebemos uma elevada distribui√ß√£o dos erros, que sugere a efetividade do modelo k-NN, em geral, de realizar boas estimativas a partir dos atributos escolhido. J√° a √°rvore de decis√£o apresenta a base alongada que define um pouco de imprecis√£o. Portanto, esses resultados podem ter chegado nesse formato devido a v√°rios fatores como a condi√ß√£o de que a √°rvore de decis√£o √© mais flex√≠vel a intera√ß√µes n√£o lineares de vari√°veis, enquanto o K-NN √© muito mais sens√≠vel a outliers ou a dados desbalanceados, j√° que esse previsor n√£o olha os dados como todo, que no nosso caso s√£o muitos, apenas os mais pr√≥ximos. \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"assets\\hist_knn.png\" alt=\"Mapa: A Batalha Final\">\n",
    "    <figcaption>Histograma dos erros do modelo KNN presente no caderno 2</figcaption>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"assets\\hist_arv.png\" alt=\"Mapa: A Batalha Final\">\n",
    "    <figcaption>Histograma dos erros do modelo √°rvore de decis√µes presente no caderno 3</figcaption>\n",
    "</div>\n",
    "\n",
    "Com isso, percebemos que se trata de uma quest√£o de qual dos dois melhor se encaixa ao nosso problema. Escolhemos levar em considera√ß√£o que a √°rvore de decis√£o apresentou melhor desempenho nos valores de MSE e RMSR, al√©m de se comportar melhor em dados com alta dimensionalidade, que √© o caso do nosso Dataframe. Dessa forma, mesmo normalizando os dados para aplicar o regressor K-NN vizinhos, escolher o valor dos vizinhos e atributos ou o uso de t√©cnicas de otimiza√ß√£o, consideramos o modelo da √°rvore de decis√µes mais efetivo nessa aplica√ß√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üê≤ Conclus√£o: Entrega da cabe√ßa do drag√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos nesse trabalho que analisar dados exige pensar sobre o contexto geral das informa√ß√µes e, ap√≥s isso, testar mais de um modelo, para conseguir comparar e entender se sua escolha foi a mais adequada. \n",
    "\n",
    "Ent√£o, a √Årvore de Decis√£o se saiu melhor que o K-NN neste cen√°rio, isso se deu provavelmente porque conseguiu capturar as intera√ß√µes e padr√µes nos dados de forma mais eficiente sem proporcionar muitos outliers.\n",
    "\n",
    "O K-NN pode n√£o ter sido ideal para esse tipo de dados, seja devido √† dimensionalidade ou √† forma como as vari√°veis se relacionam. √â poss√≠vel que o K-NN tenha sofrido de problemas de escolha inadequada de ùëò, enquanto a √Årvore de Decis√£o se moldou melhor a estrutura dos dados que esse trabalho se disp√µe a utilizar.\n",
    "\n",
    "Outra explica√ß√£o plaus√≠vel √© a diferen√ßa de atributos utilizados, como destacado em seus respectivos cadernos, o modelo k-NN utilizou atributos que foram denominados como *derivados* ao longo dos cadernos e o modelo de √°rvore de decis√£o utilizou atributos que foram denominados *diretos*. Essa diferen√ßa pode ter influenciado nos resultados, j√° que os atributos derivados podem ter sido mais sens√≠veis a outliers e a dados desbalanceados, o que pode ter prejudicado a performance do modelo k-NN.\n",
    "\n",
    "Por fim, consideramos os resultados da √°rvore satisfat√≥rios para o modelo preditivo e acreditamos que a escolha desse modelo, nesse contexto, se demonstra um objeto muito eficiente para o estudo de novos materiais para aplica√ß√£o nas c√©lulas solares. Sua capacidade de prever o *band gap* com baixo erro, pode ser um ponto de partida para a s√≠nstese de novos materiais, que possam ser mais eficientes e baratos para a produ√ß√£o de energia solar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñReferencias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k Vizinhos mais pr√≥ximos**.Dispon√≠vel em: https://link.springer.com/chapter/10.1007/978-3-031-45630-5_10\n",
    "\n",
    "CASSAR, Daniel. **Aprendizado de m√°quina, k-NN e m√©tricas**. 2024. Material de Aula.\n",
    "\n",
    "CASSAR, Daniel. **√Årvores de decis√£o**. 2024. Material de aula.\n",
    "\n",
    "**Comparando Classificadores: √Årvores de Decis√£o, K-NN e Naive Bayes**.Dispon√≠veis em: https://www.insightlab.ufc.br/comparando-classificadores-arvores-de-decisao-k-nn-e-naive-bayes/\n",
    "\n",
    "**O Algor√≠tmo k-Nearest Neighbors (kNN) em Machine Learning**. Dispon√≠vel em: https://portaldatascience.com/o-algoritmo-k-nearest-neighbors-knn-em-machine-learning/\n",
    "\n",
    "**√Årvore de decis√£o: entenda esse algoritmo de Machine Learning**. Dispon√≠vel em: https://blog.somostera.com/data-science/arvores-de-decisao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë£ **Passos anteriores**\n",
    "\n",
    "Este √© o quarto e √∫ltimo de uma s√©rie de 4 notebooks que comp√µem o trabalho final da disciplina de Aprendizado de M√°quina. Infelizmente n√£o h√° pr√≥ximo caderno. Para acompanhar o desenvolvimento do projeto, acesse os notebooks em nosso [git](https://github.com/CaioRuas24010/SepulcroDeDelfos/tree/main/A%20Batalha%20Contra%20Dragao):\n",
    "\n",
    "1. **[`introducao.ipynb`](https://github.com/CaioRuas24010/SepulcroDeDelfos/blob/main/A%20Batalha%20Contra%20Dragao/introducao.ipynb) - Baixando e organizando os dados**\n",
    "2. **[`modelo_dos_k-nn_vizinhos.ipynb`](https://github.com/CaioRuas24010/SepulcroDeDelfos/blob/main/A%20Batalha%20Contra%20Dragao/modelo_dos_k-nn_vizinhos.ipynb) - Estudando o modelo k-NN**\n",
    "3. **[`arvore_de_decisao.ipynb`](https://github.com/CaioRuas24010/SepulcroDeDelfos/blob/main/A%20Batalha%20Contra%20Dragao/arvore_de_decisao.ipynb) - Estudando o modelo √Årvore de Decis√£o**\n",
    "4. **[`conclusao.ipynb`](https://github.com/CaioRuas24010/SepulcroDeDelfos/blob/main/A%20Batalha%20Contra%20Dragao/conclusao.ipynb) - Resultados e discuss√µes finais** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **<span style=\"font-family: 'Palatino Linotype', serif;\">Fim da nossa jornada</span>**\n",
    "\n",
    "*<span style=\"font-family: 'Angilla Tattoo'\"> <br> Passamos por muitos c√≥digos e batalhas mas nosso gerreiros consegiram derrotar o mostro final! Gl√≥ria pra todos os h√©rois do Sepulcro de Delfos que embarcaram nessa jornada!! <br> <br> ‚ù§Ô∏è Mas a cima de tudo, obrigada a voc√™ ,leitor, que nos acompanhou em nossos passos, agradecemos √° sua presen√ßa em nossas miss√µes! <br> <br> Ent√£o grite conosco: Nossos algoritmos s√£o or√°culos, nossos dados s√£o ossos ancestrais. <br> Sepulcro de Delfos </span>*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
