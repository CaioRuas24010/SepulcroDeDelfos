{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"font-family: 'Palatino Linotype', serif;\">Não perca a classe!</span>**\n",
    "\n",
    "*<span style=\"font-family: 'Angilla Tattoo'\">Grandes sábios aqueles que adentram a Taverna do Sol, adoradora da grande estrela, fonte do grande patrono, Apolo.  \\o/   <br> <br> Nossos algoritmos são oráculos, nossos dados são ossos ancestrais. <br> Sepulcro de Delfos </span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelos 1 - classificador KNN**\n",
    "==========================================================\n",
    "\n",
    "**Autores:** Sepulcro de Delfos\n",
    "* Ana Luz \n",
    "* Caio Ruas\n",
    "* Caio Matheus\n",
    "* Giovana Martins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Durante as aulas na disciplina de Aprendizado de Máquinas, aprendemos que KNN é um algoritmo regressor que utiliza a distância entre os pontos para classificar novos dados. Neste caderno, nosso objetivo é transformar o algoritmo regressor feito em sala para um algoritmo classificador, alterando também o sistema da métrica de distância de distância euclidiana para distância de manhattan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código feito em sala de aula\n",
    "\n",
    "A sessão a seguir apresenta o código feito em sala de aula, que será utilizado como base para a implementação do classificador KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocorreu a preparação dos dados, sendo que utilizamos um datasetdo seaborn chamadado \"penguins\". Seguido da codificação do algorítimo regressor de KNN, finalizando com um teste com um novo penguin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as st\n",
    "import seaborn as sns\n",
    "\n",
    "NOME_DATASET = \"penguins\"\n",
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"body_mass_g\"]\n",
    "\n",
    "df = sns.load_dataset(NOME_DATASET)\n",
    "df = df.dropna()  # remove linhas com células vazia\n",
    "\n",
    "X = df.reindex(FEATURES, axis=1)\n",
    "y = df.reindex(TARGET, axis=1)\n",
    "\n",
    "X = X.values\n",
    "y = y.values.ravel()  # o método `ravel` deixa os dados em 1 dimensão\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_distancia(coordenada_1, coordenada_2):\n",
    "\n",
    "    distancia = 0\n",
    "    for c1, c2 in zip(coordenada_1, coordenada_2):\n",
    "        distancia += (c1 - c2) ** 2\n",
    "    distancia = distancia ** 0.5\n",
    "\n",
    "    return distancia\n",
    "\n",
    "\n",
    "def treinar_knn(modelo, X, y, num_vizinhos):\n",
    "\n",
    "    modelo[\"atributos\"] = X\n",
    "    modelo[\"target\"] = y\n",
    "    modelo[\"num_vizinhos\"] = num_vizinhos\n",
    "\n",
    "\n",
    "def previsao_knn(modelo, X):\n",
    "    \n",
    "    distancias = []\n",
    "    \n",
    "    for pinguin in modelo[\"atributos\"]:\n",
    "        distancia_calculada = calcula_distancia(pinguin,X)\n",
    "        distancias.append(distancia_calculada)\n",
    "    \n",
    "    indices = np.argsort(distancias)[:modelo[\"num_vizinhos\"]]\n",
    "    \n",
    "    targets = modelo[\"target\"][indices]\n",
    "    \n",
    "    y_previsto = st.mean(targets)\n",
    "        \n",
    "    \n",
    "    return y_previsto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641.6666666666665\n"
     ]
    }
   ],
   "source": [
    "modelo = {}\n",
    "\n",
    "treinar_knn(modelo, X, y, 3)\n",
    "\n",
    "x_novo = [43, 20, 180]\n",
    "\n",
    "y_previsto = previsao_knn(modelo, x_novo)\n",
    "\n",
    "print(y_previsto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações\n",
    "\n",
    "Para realizar as transformações mencionadas a cima, foram dividas as etapas nas seguintes alterações:\n",
    "\n",
    "1. A função de distância euclidiana foi substituída pela função de distância de manhattan.\n",
    "2. A função de predição foi alterada para retornar a classe mais frequente entre os vizinhos mais próximos, para transformar de um regressor para um classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente preparamos os dados, note que agora nosso target possui classes, não sendo mais númerico. Essa situação já prever que não poderemos realizar a média dos vizinhos mais póximos para fornecer uma previsão. Então como calassificar? A forma utilizada nesse algorítimo é analizar a frequeência que as classificações possíveis aparecem nos vizinhos mais próximos. Portanto, olhamos os n vizinhos mais próximos e qual classificação aparecer mais vezes será a classificação desse novo penguin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe que temos no target:['Adelie' 'Chinstrap' 'Gentoo']\n"
     ]
    }
   ],
   "source": [
    "NOME_DATASET = \"penguins\"\n",
    "FEATURES = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\n",
    "TARGET = [\"species\"] #Repare que aqui trocamos por um target com classes\n",
    "\n",
    "df = sns.load_dataset(NOME_DATASET)\n",
    "df = df.dropna()  # remove linhas com células vazia\n",
    "\n",
    "X = df.reindex(FEATURES, axis=1)\n",
    "y = df.reindex(TARGET, axis=1)\n",
    "\n",
    "X = X.values\n",
    "y = y.values.ravel()  # o método `ravel` deixa os dados em 1 dimensão\n",
    "classes = df[\"species\"].unique() #observamos as classes que o target possui\n",
    "print(f\"Classe que temos no target:{classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A função de distância euclidiana foi substituída pela função de distância de manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_distancia_manhattan(coordenada_1, coordenada_2):\n",
    "\n",
    "    distancia = 0\n",
    "    for c1, c2 in zip(coordenada_1, coordenada_2):\n",
    "        distancia += abs(c1 - c2)\n",
    "    return distancia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A função de predição foi alterada para retornar a classe mais frequente entre os vizinhos mais próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def classificadoe_KNN(modelo, X):\n",
    "    distancias = []\n",
    "    \n",
    "    for pinguin in modelo[\"atributos\"]:\n",
    "        distancia_calculada = calcula_distancia(pinguin,X)\n",
    "        distancias.append(distancia_calculada)\n",
    "    \n",
    "    indices = np.argsort(distancias)[:modelo[\"num_vizinhos\"]]\n",
    "    \n",
    "    targets = modelo[\"target\"][indices]\n",
    "    lista_targets= list(targets)\n",
    "\n",
    "    #votação = lista_targets.count()\n",
    "    #y_previsto = votação.idxmax() \n",
    "\n",
    "    contagem_votos = Counter(lista_targets)\n",
    "    y_previsto = contagem_votos.most_common(1)[0][0]      \n",
    "    \n",
    "    return y_previsto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste para classificar espécie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O pinguin [43, 20, 180] foi classificado como pertecente a espécie 3550.0\n"
     ]
    }
   ],
   "source": [
    "modelo = {}\n",
    "\n",
    "treinar_knn(modelo, X, y, 3)\n",
    "\n",
    "x_novo = [43, 20, 180]\n",
    "\n",
    "y_classificado = classificadoe_KNN(modelo, x_novo)\n",
    "\n",
    "print(f\"O pinguin {x_novo} foi classificado como pertecente a espécie {y_classificado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão\n",
    "Percebemos que a lógica por traz do algorítimo KNN não se trata de um modelo rígido, mas uma análise dos dados mais próximos para tentar prever informações sobre o novo dado. Então, não precisamos ficar restritos a targets numéricos, conseguimos abordar dados categóricos, buscando métodos como frequência, ou seja a moda, para fornecer uma previsão. Além disso, é importante perceber que o cálculo da distância também tem suas flexibilidade, em que trocamos o cálculo de distância que fornecia o menor valor possível entre dois pontos (distância euclidiana), para uma fórmula que fornece a distância percorrendo por \"grid de ruas\", o que faz com que ela não sofra muitas variações já em seus cáculos não apresenta o quadrado das difernças, observe a baixo:\n",
    "\n",
    "Distância Euclidiana\n",
    "\n",
    "A distância euclidiana entre dois pontos é dada pela fórmula:\n",
    "\n",
    "$$\n",
    "d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "$$\n",
    "\n",
    "Distância de Manhattan\n",
    "\n",
    "A distância de Manhattan entre os mesmos pontos é calculada como:\n",
    "\n",
    "$$\n",
    "d = |x_2 - x_1| + |y_2 - y_1|\n",
    "$$\n",
    "\n",
    "Resumo das Diferenças\n",
    "\n",
    "| Característica         | Distância Euclidiana                      | Distância de Manhattan               |\n",
    "|-----------------------|-------------------------------------------|--------------------------------------|\n",
    "| **Interpretação**     | Distância direta entre dois pontos       | Distância seguindo uma grade de ruas |\n",
    "| **Sensibilidade**     | Sensível a grandes variações (elevado ao quadrado) | Menos sensível a grandes variações   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "Concluimos que algorítimos possuem lógicas que não precisam ser restritas a um único modelo, mas pode atender a diferentes propostas, como no caso analisado em que uma mesma lógica KNN foi usado para uma regressão e para uma classificação. Também temos modos diferntes de pensar em distâncias que oferecem diferentes sencibilidades, as quais vamos sentir necessidade dependendo dos dados e objetivos propostos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "**O que é a distância de Manhattan?**. Disponível em:https://www.datacamp.com/pt/tutorial/manhattan-distance\n",
    "\n",
    "ASSAR, Daniel. **Aprendizado de Máquina: k-NN e Métricas**. [2024]. Material didático.\n",
    "\n",
    "**O que é e como funciona o algoritmo KNN?**. Disponível em: https://didatica.tech/o-que-e-e-como-funciona-o-algoritmo-knn/\n",
    "\n",
    "**collections — Tipos de dados de contêineres**.Disponível em: https://docs.python.org/pt-br/3/library/collections.html#collections.Counter\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
